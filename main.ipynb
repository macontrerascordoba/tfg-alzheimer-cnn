{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI CNN\n",
    "\n",
    "## Imports\n",
    "First we need to import the necesary libraries for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-11 16:12:35.825793: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-11 16:12:38.505458: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-11 16:12:38.505624: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-11 16:12:38.901169: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-11 16:12:39.899175: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-11 16:12:39.904540: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-11 16:12:43.794906: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step (Loading Data)\n",
    "\n",
    "First we create a function to load the .nii images data and get their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load .nii images\n",
    "def load_nii(file_path):\n",
    "    return np.array([nib.load(file_path).get_fdata() for file_path in file_paths])\n",
    "\n",
    "# Obtention of all .nii files paths and their imageID\n",
    "file_paths = []\n",
    "images_ids = []\n",
    "base_folder = \".data/Image_Collections/ADNI1_Annual_2_Yr_3T\"\n",
    "\n",
    "for root, dirs, files in os.walk(base_folder):\n",
    "    for file in files:\n",
    "        if file.endswith(\".nii\"):\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "            images_ids.append(file.split('.')[0])\n",
    "\n",
    "# Load labels\n",
    "labels_df = pd.read_csv('.data/Image_Collections/ADNI1_Annual_2_Yr_3T_2_20_2024.csv')  # Replace with the actual path\n",
    "labels_dict = dict(zip(labels_df['Image Data ID'], labels_df['Group']))\n",
    "labels = [labels_dict[image_data_id] for image_data_id in images_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Step (Split Data)\n",
    "\n",
    "Now we encode the obtained data and split it into the train and test subsets (We will consider adding a validation subset if we consider it necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we get the image dimensions\n",
    "\n",
    "number_of_images = len(file_paths)\n",
    "\n",
    "usable_file_paths = []\n",
    "usable_images_ids = []\n",
    "usable_labels = []\n",
    "\n",
    "for i in range(10): #range(number_of_images):\n",
    "\n",
    "    # Load the NIfTI image\n",
    "    img = nib.load(file_paths[i])\n",
    "\n",
    "    image_shape = img.shape\n",
    "    image_shape_string = f'{image_shape[0]},{image_shape[1]},{image_shape[2]}'\n",
    "\n",
    "    # Since not all the images are the same shape, we are going to use the ones with a shape of 240x256x160, since they are the most abundant\n",
    "    if image_shape_string == '240,256,160':\n",
    "        usable_file_paths.append(file_paths[i])\n",
    "        usable_images_ids.append(images_ids[i])\n",
    "        usable_labels.append(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels\n",
    "label_dict = {'CN': 0, 'MCI': 1, 'AD': 2}\n",
    "encoded_labels = tf.keras.utils.to_categorical([label_dict[label] for label in labels], num_classes=3)\n",
    "\n",
    "# Split the data\n",
    "X_train_paths, X_test_paths, y_train, y_test = train_test_split(file_paths, encoded_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Step (Build CNN Model and Copile it)\n",
    "\n",
    "Now we are going to build the CNN Model and Compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build CNN Model\n",
    "\n",
    "width, height, depth = 240, 256, 160\n",
    "channels = 1 \n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv3D(8, (3, 3, 3), activation='relu', input_shape=(width, height, depth, channels)),\n",
    "    tf.keras.layers.MaxPooling3D((2, 2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Step (Train Model)\n",
    "\n",
    "Now we need to train the model with the previously created model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom data generator\n",
    "def data_generator(file_paths, labels, batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(file_paths), batch_size):\n",
    "            batch_file_paths = file_paths[i:i+batch_size]\n",
    "            batch_labels = labels[i:i+batch_size]\n",
    "            batch_images = load_nii(batch_file_paths)\n",
    "            yield batch_images, batch_labels\n",
    "\n",
    "# Use the data generator during model training\n",
    "batch_size = 2  # Experiment with different batch sizes\n",
    "train_data_generator = data_generator(X_train_paths, y_train, batch_size)\n",
    "\n",
    "model.fit(train_data_generator, steps_per_epoch=len(X_train_paths)//batch_size, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Step (Test Model)\n",
    "\n",
    "In this step we are going to use the test subset to see how good our model did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = load_nii(X_test_paths)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
